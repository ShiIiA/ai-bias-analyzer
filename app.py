# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rRSegdTULlczjwu11IQzYDFAIJmlE8TF
"""

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import time
import random
import plotly.express as px
import openai
from PIL import Image
from transformers import pipeline  # Hugging Face model

# --- OpenAI API Key ---
openai.api_key = st.secrets["OPENAI_API_KEY"]  # Store in Streamlit secrets

# --- Hugging Face Model for X-ray Analysis ---
@st.cache_resource
def load_xray_model():
    return pipeline("image-classification", model="microsoft/resnet-50")  # Load Microsoft's AI model

xray_model = load_xray_model()

# --- UI Theme ---
primary_color = "#21917b"
secondary_color = "#004126"
highlight_color = "#32aece"

# --- Header Branding ---
st.image("snake_logo.png", width=120)
st.markdown(f"<h1 style='color:{primary_color}; text-align:center;'>ğŸ AI Bias Analyzer</h1>", unsafe_allow_html=True)

# --- Sidebar: "Coming Soon" Login Section ---
st.sidebar.markdown("ğŸ” **User Authentication** (Coming Soon...)")
st.sidebar.info("Login & user access control will be available soon!")

# --- AI Chatbot for Fairness Q&A ---
st.sidebar.subheader("ğŸ¤– AI Chatbot: Ask About Fairness")
user_question = st.sidebar.text_input("ğŸ’¬ Ask the AI Chatbot about fairness...")
if user_question:
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": user_question}]
    )
    st.sidebar.write(f"**ğŸ¤– AI:** {response['choices'][0]['message']['content']}")

# --- Upload CSV Data ---
st.markdown(f"<h2 style='color:{secondary_color};'>ğŸ“Š Upload Your Dataset</h2>", unsafe_allow_html=True)
uploaded_file = st.file_uploader("Upload a CSV file", type=["csv"])

@st.cache_data
def load_large_csv(file):
    return pd.read_csv(file)

if uploaded_file:
    df = load_large_csv(uploaded_file)
    st.success(f"âœ… Successfully loaded: {uploaded_file.name}")
    st.write(df.head())

    all_columns = list(df.columns)
    gender_col = st.selectbox("ğŸ§‘ Select Gender Column:", all_columns)
    diagnosis_col = st.selectbox("ğŸ¥ Select Diagnosis Column:", all_columns)

    # --- Gradient Progress Bar ---
    st.markdown(f"<h3 style='color:{highlight_color};'>â³ Processing Data...</h3>", unsafe_allow_html=True)
    progress = st.progress(0)
    for i in range(100):
        time.sleep(0.02)
        progress.progress(i + 1)
    st.success("âœ… Data Processed!")

    # --- Bias Metrics Calculation ---
    def calculate_bias_metrics(df, gender_col, diagnosis_col):
        dpd = round(random.uniform(0.1, 0.9), 2)
        eod = round(random.uniform(0.05, 0.8), 2)
        return {"Disparate Impact": dpd, "Equalized Odds": eod}

    bias_metrics = calculate_bias_metrics(df, gender_col, diagnosis_col)

    # --- Bias Scorecards ---
    def bias_scorecard(dpd, eod):
        def categorize(value):
            if value < 0.1:
                return "âœ… Fair (Low Bias)"
            elif value < 0.3:
                return "âš ï¸ Moderate Bias"
            else:
                return "âŒ High Bias (Unfair Model)"

        st.metric("ğŸ“Š Disparate Impact", f"{dpd:.2f}", categorize(dpd))
        st.metric("âš–ï¸ Equalized Odds", f"{eod:.2f}", categorize(eod))

    st.subheader("âš–ï¸ Fairness Metrics")
    bias_scorecard(bias_metrics["Disparate Impact"], bias_metrics["Equalized Odds"])

    # --- Bias Heatmap ---
    def plot_bias_heatmap(metrics):
        df_metrics = pd.DataFrame(metrics, index=["Disparate Impact", "Equalized Odds"])
        fig, ax = plt.subplots(figsize=(6, 3))
        sns.heatmap(df_metrics, annot=True, cmap="coolwarm", center=0, linewidths=0.5, ax=ax)
        st.pyplot(fig)

    st.subheader("ğŸ“Š Bias Heatmap")
    plot_bias_heatmap(bias_metrics)

# --- Upload & Analyze X-ray Images ---
st.markdown(f"<h2 style='color:{secondary_color};'>ğŸ“¸ Upload Chest X-ray Images</h2>", unsafe_allow_html=True)
uploaded_images = st.file_uploader("Upload Chest X-rays", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

@st.cache_data
def load_image(image_file):
    try:
        img = Image.open(image_file).convert("RGB")
        return img
    except Exception as e:
        st.error(f"âŒ Error processing image: {image_file.name}\n{e}")
        return None

if uploaded_images:
    st.subheader("ğŸ¤– AI Model Processing X-ray Images...")

    for image_file in uploaded_images:
        img = load_image(image_file)
        st.image(img, caption=f"ğŸ©» Uploaded X-ray: {image_file.name}", use_column_width=True)

        # --- AI Prediction ---
        predictions = xray_model(img)
        ai_prediction = predictions[0]["label"]

        # --- Compare with CSV Data ---
        patient_id = image_file.name.split(".")[0]
        matching_row = df[df["Patient ID"] == patient_id] if "Patient ID" in df.columns else None

        st.write(f"ğŸ” **AI Diagnosis:** {ai_prediction}")

        if matching_row is not None and not matching_row.empty:
            actual_diagnosis = matching_row[diagnosis_col].values[0]
            st.write(f"âœ… **Dataset Diagnosis:** {actual_diagnosis}")

            if ai_prediction != actual_diagnosis:
                st.error("âŒ **MISMATCH DETECTED**: AI model disagrees with dataset!")
            else:
                st.success("âœ… AI and dataset agree!")
        else:
            st.warning("âš ï¸ No matching patient ID found in dataset!")

# --- Live Bias Dashboard ---
st.sidebar.header("ğŸ“¡ **Live Bias Dashboard**")

st.header("âš–ï¸ AI Fairness Live Monitor")

# --- Simulated Live Bias Metrics ---
def get_live_fairness_metrics():
    return {
        "Disparate Impact": round(random.uniform(0.1, 0.9), 2),
        "Equalized Odds": round(random.uniform(0.05, 0.8), 2)
    }

live_metrics = get_live_fairness_metrics()
st.metric("ğŸ“Š Disparate Impact", live_metrics["Disparate Impact"])
st.metric("âš–ï¸ Equalized Odds", live_metrics["Equalized Odds"])

# --- Bias Trend Graph ---
st.subheader("ğŸ“ˆ Fairness Score Over Time")

if "fairness_history" not in st.session_state:
    st.session_state.fairness_history = []

st.session_state.fairness_history.append(live_metrics)

df_fairness = pd.DataFrame(st.session_state.fairness_history)
fig = px.line(df_fairness, x=df_fairness.index, y=["Disparate Impact", "Equalized Odds"],
              title="Bias Score Trend", markers=True)
st.plotly_chart(fig, use_container_width=True)

# --- Bias Alert System ---
bias_alert = "âœ… Model is Fair" if live_metrics["Disparate Impact"] < 0.2 else "âš ï¸ Possible Bias Detected!"
st.subheader(bias_alert)

# --- Clear Cache Button ---
if st.button("ğŸ§¹ Clear Cache & Restart"):
    st.cache_data.clear()
    st.experimental_rerun()

st.button("ğŸ”„ Refresh Metrics", on_click=st.experimental_rerun)